<br />
<div align="center">

  <h3 align="center">Sistemas Distribuidos: Tarea 02</h3>

  <p align="center">
    Fernando Bur√≥n, Felipe Condore
  </p>
</div>


## Acerca del proyecto

El objetivo de esta tarea consiste en poner en pr√°ctica el concepto de Streaming, visto en clases y presentaciones. Para ello se debe hacer uso de tecnlog√≠as que permitan la soluci√≥n a esta problem√°tica



### üõ† Constru√≠do con:

Esta secci√≥n muestra las tecnolog√≠as con las que fue constru√≠do el proyecto.

* [Apache Kafka](https://kafka.apache.org)
* [Postgres](https://www.postgresql.org)
* [Python](https://www.python.org)
* [Docker](https://www.docker.com)


## üî∞ Comenzando

Para iniciar el proyecto, primero hay que copiar el repositorio `git clone https://github.com/Buronn/SD-T2-kafka`, ingresar a √©l `/cd SD-T2-kafka` y escribir el siguiente comando en la consola:
* docker
```sh
docker-compose build
```
Para que los contenedores se inician en el ambiente local se utiliza el siguiente comando en la consola:
* docker
```sh
docker-compose up -d
```
### Pre-Requisitos

Tener Docker y Docker Compose instalado
* [Installation Guide](https://docs.docker.com/compose/install/)



## ü§ù Uso

La aplicaci√≥n tiene dos API dispoble, una en el puerto 3000 (LOGIN) y otra en el 5000 (BLOCKED).

### API-LOGIN
Inicia sesi√≥n, si se hace 5 inicios incorrectos, en [API-BLOCKED](./readme.md/###API-BLOCKED)
```sh
curl --location --request POST http://localhost:3000/login \
--header 'Content-Type: application/json' \
--data-raw '{
    "user":"user",
    "pass":"password"
}'
```
#### 
- ‚òÑ M√âTODO: POST
- ‚ùî   CONTENT-TYPE: application/json
- üìÑ  DATA-RAW: user y password en formato json

#### Response example
```js
// En caso de colocar una contrase√±a incorrecta
{
    "error":"Wrong password"
}
// En caso de colocar correctamente los datos
{
    "success":True
}
```
En caso de que se deba registrar un usuario, utilizar la siguiente petici√≥n:
```sh
curl --location --request POST 'localhost:3000/register' \
--header 'Content-Type: application/json' \
--data-raw '{
    "user":"test",
    "pass":"test1234"
}'
```
### API-BLOCKED
Muestra los usuarios bloqueados por muchos intentos fallidos
```sh
curl ‚àí‚àílocation ‚àí‚àírequest GET http://localhost:5000/blocked
```
#### 
- ‚òÑ M√âTODO: GET
#### Response
```js
{
    "users-blocked":[
      "user1",
      "user2"
    ]
}
```
## ‚ùî Preguntas

### 1 ¬øPor qu√© Kafka funciona bien en este escenario?
Kafka es un software que permite el flujo y env√≠o de informaci√≥n en gran volumen a trav√©s de su sistema de t√≥picos (brokers). Esto √∫ltimo permite a los servicios de Login y Bloqueo trabajar de manera as√≠ncrona gracias al modelo productor/consumidor, dado que el servicio de Login es capaz de informar en el t√≥pico de kafka cuales son las cuentas que han tratado de iniciar sesi√≥n de manera fallida, sin necesidad de esperar a que el servicio de bloqueo realice alguna acci√≥n, puesto que kafka se encarga de almacenar esto en el t√≥pico el cual puede ser consumido por el servicio de Bloqueo en cualquier otro momento. 

Esto se traduce en un menor tiempo de respuesta para el usuario que est√© utilizando el cliente o aplicaci√≥n, ya que de no utilizar kafka la aplicaci√≥n estar√≠a esperando la respuesta del servicio de bloqueo (parecido a un modelo cliente/servidor) que en t√©rminos de escalabilidad resulta ineficiente, generando un cuello de botella que colapsar√≠a este servicio.

### 2 Basado en las tecnolog√≠as que usted tiene a su disposici√≥n (Kafka, backend) ¬øQu√© har√≠a usted para manejar una gran cantidad de usuarios al mismo tiempo?
Una opci√≥n inicial ser√≠a escalar kafka con m√°s brokers o equipos de manera distribuida para lograr comunicar una mayor cantidad de datos en tiempo real. Adicional a esto √∫ltimo, tambi√©n ser√≠a una buena opci√≥n distribuir el servicio de bloqueos agregando los siguientes servicios.

####
- Apache Flink: Flink es una herramienta de procesamiento de flujo en tiempo real y de c√≥digo abierto, cuya funcionalidad radica en el procesamiento de m√∫ltiples tareas realizas simult√°neamente en tiempo real, basado en alg√∫n tipo de input que provean datos y output donde se escribir o guardar los resultados obtenidos de estos procesamientos. Esta herramienta es ideal, puesto que nos permitir√≠a consumir el t√≥pico de kafka que contiene la lista de logins de usuarios, y determinar en tiempo real cuales cuentas deber√°n ser bloquedas.

- Redis: Es una base de datos en memoria NoSQL que se usa principalmente para la obtenci√≥n de warmdata. En este servicio se almacenar√≠an los resultados tras el procesamiento del servicio de flink, los cuales ser√≠an consumidos a trav√©s de la API del servicio de bloqueo.
####

A partir de esta arquitectura, ser√° posible manejar una gran cantidad de usuarios en tiempo real, puesto que el servicio de bloqueo solamente accede a los datos almacenados en cache (Redis). El trabajo de procesamiento y an√°lisis para determinar en el tiempo cuales cuentas corresponde a ser bloqueadas es llevado a cabo por Flink. Evitando lecturas y escrituras de archivos de manera ineficiente que solo empeora el rendimiento del sistema.

## ‚Ñπ Informaci√≥n Importante
El uso de las im√°genes de [Bitnami](https://hub.docker.com/u/bitnami) fueron reemplazadas por [wurstmeister](https://hub.docker.com/u/wurstmeister) por el simple hecho de que la utilizaci√≥n de [AIOKafka](https://github.com/aio-libs/aiokafka) no permit√≠a establecer una conexi√≥n con el contenedor de Kafka. Esta librer√≠a de Python permite utilizar Kafka de manera asincr√≥nica, exactamente lo que se requer√≠a para combinar Flask con un KafkaProducer. Para el api de bloqueo se us√≥ un KafkaProducer as√≠ncrono basado en la contribuci√≥n de trabajo de [NimzyMaina](https://github.com/NimzyMaina/flask_kafka).
